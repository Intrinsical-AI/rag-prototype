    ):
        # Arrange
        # 1. Asegurar que se usará OpenAIGenerator y que tiene una API key para __init__
        monkeypatch.setattr(settings, "ollama_enabled", False)
        current_openai_api_key = settings.openai_api_key # Guardar por si se parchea
        if settings.openai_api_key is None or settings.openai_api_key == "sk-dummy-test-key": # Evitar sobreescribir una real
            monkeypatch.setattr(settings, "openai_api_key", "sk-integration-openai-ask")
    
        # 2. Configurar el mock para la clase OpenAI
        mock_openai_client_instance = MockOpenAIClass.return_value
        expected_answer = "Mocked AI answer about our refund policy."
        mock_openai_client_instance.chat.completions.create.return_value = _make_openai_v1_mock(expected_answer)
    
        # 3. Forzar la re-inicialización de RagService para que use el OpenAIGenerator
        #    que a su vez usará la clase OpenAI mockeada.
        #    Y para que el retriever se cree con el modo correcto si lo cambiamos.
        monkeypatch.setattr(settings, "retrieval_mode", "sparse") # Asegurar modo para aserción de source_id
        importlib.reload(app_dependencies_module) # Recargar para que vea los settings parcheados
        app_dependencies_module.init_rag_service() # Recrea _rag_service
    
        question_text = "What is the refund policy?"
        payload = {"question": question_text}
    
        # Act
        response = client.post("/api/ask", json=payload)
    
        # Assert
        assert response.status_code == 200
        body = response.json()
        assert body["answer"] == expected_answer
        assert isinstance(body["source_ids"], list)
>       assert 1 in body["source_ids"] # Basado en datos de prueba en conftest.py
E       assert 1 in []

tests/integration/test_api_ask.py:83: AssertionError
---------------------------------------------------------------------------------------------------------------------------- Captured log setup ----------------------------------------------------------------------------------------------------------------------------
WARNING  src.adapters.retrieval.sparse_bm25:sparse_bm25.py:34 WARNING: Document corpus it's empty. BM25 will not be initialized.
---------------------------------------------------------------------------------------------------------------------------- Captured log call -----------------------------------------------------------------------------------------------------------------------------
WARNING  src.adapters.retrieval.sparse_bm25:sparse_bm25.py:34 WARNING: Document corpus it's empty. BM25 will not be initialized.
ERROR    src.core.rag:rag.py:66 SQLAlchemyError while saving Q&A to history. Q: 'What is the refund policy?...'. Error: (sqlite3.OperationalError) no such table: qa_history
[SQL: INSERT INTO qa_history (question, answer) VALUES (?, ?) RETURNING id, created_at]
[parameters: ('What is the refund policy?', 'Mocked AI answer about our refund policy.')]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlite3.OperationalError: no such table: qa_history

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/src/core/rag.py", line 63, in ask
    crud.add_history(db, question, answer)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/src/db/crud.py", line 23, in add_history
    db.commit()
    ~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "<string>", line 2, in commit
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    ~~~~~~~~~~~~~~~~~~^^
  File "<string>", line 2, in _prepare_impl
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    ~~~~~~~~~~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4353, in flush
    self._flush(objects)
    ~~~~~~~~~~~^^^^^^^^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4488, in _flush
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4449, in _flush
    flush_context.execute()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    ~~~~~~~~~~~^^^^^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.mapper,
        ^^^^^^^^^^^^
        uow.states_for_mapper_hierarchy(self.mapper, False, False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        uow,
        ^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        base_mapper,
        ^^^^^^^^^^^^
    ...<3 lines>...
        insert,
        ^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py", line 1233, in _emit_insert_statements
    result = connection.execute(
        statement,
        params,
        execution_options=execution_options,
    )
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1416, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1843, in _execute_context
    return self._exec_single_context(
           ~~~~~~~~~~~~~~~~~~~~~~~~~^
        dialect, context, statement, parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e, str_statement, effective_parameters, cursor, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: qa_history
[SQL: INSERT INTO qa_history (question, answer) VALUES (?, ?) RETURNING id, created_at]
[parameters: ('What is the refund policy?', 'Mocked AI answer about our refund policy.')]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
_____________________________________________________________________________________________________________ test_api_ask_with_ollama_retrieves_and_generates _____________________________________________________________________________________________________________

mock_requests_post = <MagicMock name='post' id='140316775216336'>, client = <starlette.testclient.TestClient object at 0x7f9e0b7bdbd0>, monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9e08778050>

    @mock.patch("requests.post") # Path donde requests.post es llamado por OllamaGenerator
    def test_api_ask_with_ollama_retrieves_and_generates(
        mock_requests_post,
        client: TestClient,
        monkeypatch
    ):
        # Arrange
        # 1. Habilitar Ollama y deshabilitar retrieval denso para simplificar
        monkeypatch.setattr(settings, "ollama_enabled", True)
        monkeypatch.setattr(settings, "retrieval_mode", "sparse") # O el modo que quieras probar
    
        # 2. Configurar mock para requests.post (Ollama)
        expected_answer = "Mocked Ollama answer regarding support."
        mock_ollama_response_obj = mock.MagicMock()
        mock_ollama_response_obj.json.return_value = {"response": expected_answer}
        mock_ollama_response_obj.status_code = 200
        mock_ollama_response_obj.raise_for_status.return_value = None
        mock_requests_post.return_value = mock_ollama_response_obj
    
        # 3. Forzar la re-inicialización de RagService para que use OllamaGenerator
        #    y el retriever correcto.
        importlib.reload(app_dependencies_module)
        app_dependencies_module.init_rag_service()
    
        question_text = "How to contact support?"
        payload = {"question": question_text}
    
        # Act
        response = client.post("/api/ask", json=payload)
    
        # Assert
        assert response.status_code == 200
        body = response.json()
        assert body["answer"] == expected_answer
>       assert 2 in body["source_ids"] # Basado en datos de prueba en conftest.py
E       assert 2 in []

tests/integration/test_api_ask.py:129: AssertionError
---------------------------------------------------------------------------------------------------------------------------- Captured log setup ----------------------------------------------------------------------------------------------------------------------------
WARNING  src.adapters.retrieval.sparse_bm25:sparse_bm25.py:34 WARNING: Document corpus it's empty. BM25 will not be initialized.
---------------------------------------------------------------------------------------------------------------------------- Captured log call -----------------------------------------------------------------------------------------------------------------------------
WARNING  src.adapters.retrieval.sparse_bm25:sparse_bm25.py:34 WARNING: Document corpus it's empty. BM25 will not be initialized.
ERROR    src.core.rag:rag.py:66 SQLAlchemyError while saving Q&A to history. Q: 'How to contact support?...'. Error: (sqlite3.OperationalError) no such table: qa_history
[SQL: INSERT INTO qa_history (question, answer) VALUES (?, ?) RETURNING id, created_at]
[parameters: ('How to contact support?', 'Mocked Ollama answer regarding support.')]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlite3.OperationalError: no such table: qa_history

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/src/core/rag.py", line 63, in ask
    crud.add_history(db, question, answer)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/src/db/crud.py", line 23, in add_history
    db.commit()
    ~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "<string>", line 2, in commit
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    ~~~~~~~~~~~~~~~~~~^^
  File "<string>", line 2, in _prepare_impl
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    ~~~~~~~~~~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4353, in flush
    self._flush(objects)
    ~~~~~~~~~~~^^^^^^^^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4488, in _flush
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4449, in _flush
    flush_context.execute()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    ~~~~~~~~~~~^^^^^^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.mapper,
        ^^^^^^^^^^^^
        uow.states_for_mapper_hierarchy(self.mapper, False, False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        uow,
        ^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        base_mapper,
        ^^^^^^^^^^^^
    ...<3 lines>...
        insert,
        ^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py", line 1233, in _emit_insert_statements
    result = connection.execute(
        statement,
        params,
        execution_options=execution_options,
    )
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1416, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1843, in _execute_context
    return self._exec_single_context(
           ~~~~~~~~~~~~~~~~~~~~~~~~~^
        dialect, context, statement, parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e, str_statement, effective_parameters, cursor, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/jd/Documentos/IntrinsicalAI/Repositories/local-rag-backend/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: qa_history
[SQL: INSERT INTO qa_history (question, answer) VALUES (?, ?) RETURNING id, created_at]
[parameters: ('How to contact support?', 'Mocked Ollama answer regarding support.')]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
_________________________________________________________________________________________________________________________ test_build_index_sparse __________________________________________________________________________________________________________________________

self = <sqlalchemy.engine.base.Connection object at 0x7f9e0b7f61a0>, dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f9e0b666650>, context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f9e08bf6360>

    def _exec_insertmany_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for an "insertmanyvalues"
        operation, which will invoke DBAPI
        cursor.execute() one or more times with individual log and
        event hook calls.
    
        """
    
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
        else:
            generic_setinputsizes = None
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters = parameters
    
        engine_events = self._has_events or self.engine._has_events
        if self.dialect._has_events:
            do_execute_dispatch: Iterable[Any] = (
                self.dialect.dispatch.do_execute
            )
        else:
            do_execute_dispatch = ()
    
        if self._echo:
            stats = context._get_cache_stats() + " (insertmanyvalues)"
    
        preserve_rowcount = context.execution_options.get(
            "preserve_rowcount", False
        )
        rowcount = 0
    
        for imv_batch in dialect._deliver_insertmanyvalues_batches(
            self,
            cursor,
            str_statement,
            effective_parameters,
            generic_setinputsizes,
            context,
        ):
            if imv_batch.processed_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor,
                        imv_batch.processed_setinputsizes,
                        context,
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e,
                        sql_util._long_statement(imv_batch.replaced_statement),
                        imv_batch.replaced_parameters,
                        None,
                        context,
                        is_sub_exec=True,
                    )
    
            sub_stmt = imv_batch.replaced_statement
            sub_params = imv_batch.replaced_parameters
    
            if engine_events:
                for fn in self.dispatch.before_cursor_execute:
                    sub_stmt, sub_params = fn(
                        self,
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                        True,
                    )
    
            if self._echo:
                self._log_info(sql_util._long_statement(sub_stmt))
    
                imv_stats = f""" {imv_batch.batchnum}/{
                            imv_batch.total_batches
                } ({
                    'ordered'
                    if imv_batch.rows_sorted else 'unordered'
                }{
                    '; batch not supported'
                    if imv_batch.is_downgraded
                    else ''
                })"""
    
                if imv_batch.batchnum == 1:
                    stats += imv_stats
                else:
                    stats = f"insertmanyvalues{imv_stats}"
    
                if not self.engine.hide_parameters:
                    self._log_info(
                        "[%s] %r",
                        stats,
                        sql_util._repr_params(
                            sub_params,
                            batches=10,
                            ismulti=False,
                        ),
                    )
                else:
                    self._log_info(
                        "[%s] [SQL parameters hidden due to "
                        "hide_parameters=True]",
                        stats,
                    )
    
            try:
                for fn in do_execute_dispatch:
                    if fn(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    ):
                        break
                else:
>                   dialect.do_execute(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    )

.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2115: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f9e0b666650>, cursor = <sqlite3.Cursor object at 0x7f9e05c10140>, statement = 'INSERT INTO documents (content) VALUES (?) RETURNING id', parameters = ('q1 a1',)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f9e08bf6360>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: no such table: documents

.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:945: OperationalError

The above exception was the direct cause of the following exception:

tmp_path = PosixPath('/tmp/pytest-of-jd/pytest-57/test_build_index_sparse0'), monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9e08772eb0>

    def test_build_index_sparse(tmp_path: Path, monkeypatch):
        db_file = tmp_path / "app_sparse.db"
        csv_file = tmp_path / "kb_sparse.csv"
    
        rows = [["question", "answer"], ["q1", "a1"], ["q2", "a2"]]
        with csv_file.open("w", newline="", encoding="utf-8") as fh:
            csv.writer(fh, delimiter=";").writerows(rows)
    
        # patch settings
        monkeypatch.setattr(st, "faq_csv", str(csv_file))
        monkeypatch.setattr(st, "csv_has_header", True)
        monkeypatch.setattr(st, "sqlite_url", f"sqlite:///{db_file}")
        monkeypatch.setattr(st, "retrieval_mode", "sparse")
    
        importlib.reload(db_base)  # refrezca engine de src.db.base
    
>       build_index.main()

tests/unit/test_build.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
scripts/build_index.py:82: in main
    add_documents(session, texts)
src/db/crud.py:17: in add_documents
    db.commit()
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:2032: in commit
    trans.commit(_to_root=True)
<string>:2: in commit
    ???
.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py:139: in _go
    ret_value = fn(self, *arg, **kw)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:1313: in commit
    self._prepare_impl()
<string>:2: in _prepare_impl
    ???
.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py:139: in _go
    ret_value = fn(self, *arg, **kw)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:1288: in _prepare_impl
    self.session.flush()
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:4353: in flush
    self._flush(objects)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:4488: in _flush
    with util.safe_reraise():
.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:4449: in _flush
    flush_context.execute()
.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py:1143: in _emit_insert_statements
    result = connection.execute(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
.venv/lib/python3.13/site-packages/sqlalchemy/sql/elements.py:523: in _execute_on_connection
    return connection._execute_clauseelement(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1638: in _execute_clauseelement
    ret = self._execute_context(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_insertmany_context(dialect, context)
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2123: in _exec_insertmany_context
    self._handle_dbapi_exception(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2352: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2115: in _exec_insertmany_context
    dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f9e0b666650>, cursor = <sqlite3.Cursor object at 0x7f9e05c10140>, statement = 'INSERT INTO documents (content) VALUES (?) RETURNING id', parameters = ('q1 a1',)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f9e08bf6360>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: documents
E       [SQL: INSERT INTO documents (content) VALUES (?) RETURNING id]
E       [parameters: ('q1 a1',)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:945: OperationalError
__________________________________________________________________________________________________________________________ test_build_index_dense __________________________________________________________________________________________________________________________

self = <sqlalchemy.engine.base.Connection object at 0x7f9e0873a9c0>, dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f9f19cf0e90>, context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f9e08bf6cf0>

    def _exec_insertmany_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for an "insertmanyvalues"
        operation, which will invoke DBAPI
        cursor.execute() one or more times with individual log and
        event hook calls.
    
        """
    
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
        else:
            generic_setinputsizes = None
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters = parameters
    
        engine_events = self._has_events or self.engine._has_events
        if self.dialect._has_events:
            do_execute_dispatch: Iterable[Any] = (
                self.dialect.dispatch.do_execute
            )
        else:
            do_execute_dispatch = ()
    
        if self._echo:
            stats = context._get_cache_stats() + " (insertmanyvalues)"
    
        preserve_rowcount = context.execution_options.get(
            "preserve_rowcount", False
        )
        rowcount = 0
    
        for imv_batch in dialect._deliver_insertmanyvalues_batches(
            self,
            cursor,
            str_statement,
            effective_parameters,
            generic_setinputsizes,
            context,
        ):
            if imv_batch.processed_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor,
                        imv_batch.processed_setinputsizes,
                        context,
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e,
                        sql_util._long_statement(imv_batch.replaced_statement),
                        imv_batch.replaced_parameters,
                        None,
                        context,
                        is_sub_exec=True,
                    )
    
            sub_stmt = imv_batch.replaced_statement
            sub_params = imv_batch.replaced_parameters
    
            if engine_events:
                for fn in self.dispatch.before_cursor_execute:
                    sub_stmt, sub_params = fn(
                        self,
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                        True,
                    )
    
            if self._echo:
                self._log_info(sql_util._long_statement(sub_stmt))
    
                imv_stats = f""" {imv_batch.batchnum}/{
                            imv_batch.total_batches
                } ({
                    'ordered'
                    if imv_batch.rows_sorted else 'unordered'
                }{
                    '; batch not supported'
                    if imv_batch.is_downgraded
                    else ''
                })"""
    
                if imv_batch.batchnum == 1:
                    stats += imv_stats
                else:
                    stats = f"insertmanyvalues{imv_stats}"
    
                if not self.engine.hide_parameters:
                    self._log_info(
                        "[%s] %r",
                        stats,
                        sql_util._repr_params(
                            sub_params,
                            batches=10,
                            ismulti=False,
                        ),
                    )
                else:
                    self._log_info(
                        "[%s] [SQL parameters hidden due to "
                        "hide_parameters=True]",
                        stats,
                    )
    
            try:
                for fn in do_execute_dispatch:
                    if fn(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    ):
                        break
                else:
>                   dialect.do_execute(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    )

.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2115: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f9f19cf0e90>, cursor = <sqlite3.Cursor object at 0x7f9e311985c0>, statement = 'INSERT INTO documents (content) VALUES (?) RETURNING id', parameters = ('d1 a1',)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f9e08bf6cf0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: no such table: documents

.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:945: OperationalError

The above exception was the direct cause of the following exception:

tmp_path = PosixPath('/tmp/pytest-of-jd/pytest-57/test_build_index_dense0'), monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9e0873b110>

    def test_build_index_dense(tmp_path: Path, monkeypatch):
        db_file = tmp_path / "app_dense.db"
        csv_file = tmp_path / "kb_dense.csv"
        index_file = tmp_path / "index.faiss"
        id_map_file = tmp_path / "id_map.pkl"
    
        rows = [["question", "answer"], ["d1", "a1"], ["d2", "a2"]]
        with csv_file.open("w", newline="", encoding="utf-8") as fh:
            csv.writer(fh, delimiter=";").writerows(rows)
    
        monkeypatch.setattr(st, "faq_csv", str(csv_file))
        monkeypatch.setattr(st, "csv_has_header", True)
        monkeypatch.setattr(st, "sqlite_url", f"sqlite:///{db_file}")
        monkeypatch.setattr(st, "index_path", str(index_file))
        monkeypatch.setattr(st, "id_map_path", str(id_map_file))
        monkeypatch.setattr(st, "retrieval_mode", "dense")
    
        importlib.reload(db_base)
    
>       build_index.main()

tests/unit/test_build.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
scripts/build_index.py:82: in main
    add_documents(session, texts)
src/db/crud.py:17: in add_documents
    db.commit()
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:2032: in commit
    trans.commit(_to_root=True)
<string>:2: in commit
    ???
.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py:139: in _go
    ret_value = fn(self, *arg, **kw)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:1313: in commit
    self._prepare_impl()
<string>:2: in _prepare_impl
    ???
.venv/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py:139: in _go
    ret_value = fn(self, *arg, **kw)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:1288: in _prepare_impl
    self.session.flush()
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:4353: in flush
    self._flush(objects)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:4488: in _flush
    with util.safe_reraise():
.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py:4449: in _flush
    flush_context.execute()
.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
.venv/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
.venv/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py:1143: in _emit_insert_statements
    result = connection.execute(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
.venv/lib/python3.13/site-packages/sqlalchemy/sql/elements.py:523: in _execute_on_connection
    return connection._execute_clauseelement(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1638: in _execute_clauseelement
    ret = self._execute_context(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1841: in _execute_context
    return self._exec_insertmany_context(dialect, context)
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2123: in _exec_insertmany_context
    self._handle_dbapi_exception(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2352: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2115: in _exec_insertmany_context
    dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f9f19cf0e90>, cursor = <sqlite3.Cursor object at 0x7f9e311985c0>, statement = 'INSERT INTO documents (content) VALUES (?) RETURNING id', parameters = ('d1 a1',)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f9e08bf6cf0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: documents
E       [SQL: INSERT INTO documents (content) VALUES (?) RETURNING id]
E       [parameters: ('d1 a1',)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:945: OperationalError
___________________________________________________________________________________________________________ test_choose_generator_all_fail_raises_runtime_error ____________________________________________________________________________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9f1771cd70>, mock_requests_get_fixture = <MagicMock name='get' id='140316773069696'>

    def test_choose_generator_all_fail_raises_runtime_error(monkeypatch, mock_requests_get_fixture):
        monkeypatch.setattr(global_settings, "ollama_enabled", True) # Intentará Ollama
        monkeypatch.setattr(global_settings, "openai_api_key", None) # No hay OpenAI
        mock_requests_get_fixture.side_effect = requests.exceptions.RequestException("Ollama always fails")
    
        importlib.reload(app_dependencies_module)
        with pytest.raises(RuntimeError, match="LLM Generator could not be initialized"):
>           app_dependencies_module._choose_generator()

tests/unit/test_dependencies.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _choose_generator() -> GeneratorPort:
        """Lógica para elegir Ollama u OpenAI según settings y health checks."""
        ollama_ok = False
        if settings.ollama_enabled:
            try:
                resp = requests.get(f"{settings.ollama_base_url.rstrip('/')}/api/tags", timeout=2)
                if resp.status_code == 200:
                    logger.info("Ollama habilitado y accesible; usando OllamaGenerator.")
                    ollama_ok = True
                    return OllamaGenerator()
                else:
                    logger.warning("OLLAMA_ENABLED=true pero /api/tags devolvió %d", resp.status_code)
            except requests.RequestException as e:
                logger.warning("OLLAMA_ENABLED pero no se conecta a %s: %s", settings.ollama_base_url, e)
    
        if settings.openai_api_key:
            logger.info("OpenAI API key encontrada; usando OpenAIGenerator.")
            return OpenAIGenerator()
    
        # Fallback a Ollama
        if not ollama_ok:
            logger.info("Sin OpenAI key; intentando fallback a Ollama...")
            try:
                resp = requests.get(f"{settings.ollama_base_url.rstrip('/')}/api/tags", timeout=2)
                if resp.status_code == 200:
                    logger.info("Fallback Ollama OK; usando OllamaGenerator.")
                    return OllamaGenerator()
                else:
                    logger.warning("Fallback Ollama /api/tags devolvió %d", resp.status_code)
            except requests.RequestException as e:
                logger.warning("Fallback Ollama no accesible: %s", e)
    
        error_msg = (
            "LLM Generator no pudo inicializarse. "
            "Por favor define OPENAI_API_KEY o asegúrate de que Ollama esté corriendo."
        )
        logger.error(error_msg)
>       raise RuntimeError(error_msg)
E       RuntimeError: LLM Generator no pudo inicializarse. Por favor define OPENAI_API_KEY o asegúrate de que Ollama esté corriendo.

src/app/dependencies.py:76: RuntimeError

During handling of the above exception, another exception occurred:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9f1771cd70>, mock_requests_get_fixture = <MagicMock name='get' id='140316773069696'>

    def test_choose_generator_all_fail_raises_runtime_error(monkeypatch, mock_requests_get_fixture):
        monkeypatch.setattr(global_settings, "ollama_enabled", True) # Intentará Ollama
        monkeypatch.setattr(global_settings, "openai_api_key", None) # No hay OpenAI
        mock_requests_get_fixture.side_effect = requests.exceptions.RequestException("Ollama always fails")
    
        importlib.reload(app_dependencies_module)
>       with pytest.raises(RuntimeError, match="LLM Generator could not be initialized"):
E       AssertionError: Regex pattern did not match.
E        Regex: 'LLM Generator could not be initialized'
E        Input: 'LLM Generator no pudo inicializarse. Por favor define OPENAI_API_KEY o asegúrate de que Ollama esté corriendo.'

tests/unit/test_dependencies.py:124: AssertionError
---------------------------------------------------------------------------------------------------------------------------- Captured log call -----------------------------------------------------------------------------------------------------------------------------
WARNING  src.app.dependencies:dependencies.py:52 OLLAMA_ENABLED pero no se conecta a http://localhost:11434: Ollama always fails
WARNING  src.app.dependencies:dependencies.py:69 Fallback Ollama no accesible: Ollama always fails
ERROR    src.app.dependencies:dependencies.py:75 LLM Generator no pudo inicializarse. Por favor define OPENAI_API_KEY o asegúrate de que Ollama esté corriendo.
___________________________________________________________________________________________________ test_init_rag_service_dense_mode_fallback_to_sparse_if_files_missing ___________________________________________________________________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9e08786670>, mock_path_is_file_fixture = <MagicMock name='is_file' id='140321311480128'>, caplog = <_pytest.logging.LogCaptureFixture object at 0x7f9e0b6a3230>, reset_rag_service_singleton = None

    def test_init_rag_service_dense_mode_fallback_to_sparse_if_files_missing(
        monkeypatch,
        mock_path_is_file_fixture, # Esta fixture con patch.object(Path, 'is_file') está bien
        caplog, # <-------------------- USA CAPLOG
        reset_rag_service_singleton
    ):
        # Arrange
        with AppSessionLocal() as db:
            db.query(DbDocument).delete()
            db.add_all([DbDocument(content="doc1"), DbDocument(content="doc2")])
            db.commit()
    
        monkeypatch.setattr(global_settings, "retrieval_mode", "dense")
        mock_path_is_file_fixture.return_value = False # is_file() mockeado siempre devolverá False
        monkeypatch.setattr(global_settings, "openai_api_key", "sk-testkey")
        monkeypatch.setattr(global_settings, "csv_has_header", True) # Asegúrate que esto esté si la lógica lo necesita
    
        # CONFIGURA CAPLOG
        # El logger en src/app/dependencies.py se llama 'src.app.dependencies'
        caplog.set_level(logging.WARNING, logger="src.app.dependencies")
    
        # importlib.reload(app_dependencies_module)
    
        # Imprime la configuración del engine de la SessionLocal que usará init_rag_service
        from src.db.base import SessionLocal as SL_in_deps # La que importa dependencies
        print(f"DEBUG TEST - Engine URL from SessionLocal in deps: {SL_in_deps.kw['bind'].url}")
    
        # Act
        app_dependencies_module.init_rag_service()
        service = app_dependencies_module.get_rag_service()
    
        # Assert
        assert service is not None
        assert isinstance(service.retriever, SparseBM25Retriever)
    
        found_warning_log = False
        # print(f"Caplog text for fallback test: {caplog.text}") # Para depurar
        for record in caplog.records:
            if record.name == "src.app.dependencies" and \
               record.levelname == "WARNING" and \
               "Falling back to sparse retrieval" in record.message:
                found_warning_log = True
                break
>       assert found_warning_log, f"Expected fallback warning log was not found. Captured logs:\n{caplog.text}"
E       AssertionError: Expected fallback warning log was not found. Captured logs:
E         WARNING  src.app.dependencies:dependencies.py:133 Dense seleccionado pero faltan index/id_map; fallback a sparse.
E         WARNING  src.adapters.retrieval.sparse_bm25:sparse_bm25.py:34 WARNING: Document corpus it's empty. BM25 will not be initialized.
E         
E       assert False

tests/unit/test_dependencies.py:182: AssertionError
--------------------------------------------------------------------------------------------------------------------------- Captured stdout call ---------------------------------------------------------------------------------------------------------------------------
DEBUG TEST - Engine URL from SessionLocal in deps: sqlite:////tmp/pytest-of-jd/pytest-57/test_build_index_dense0/app_dense.db
---------------------------------------------------------------------------------------------------------------------------- Captured log call -----------------------------------------------------------------------------------------------------------------------------
WARNING  src.app.dependencies:dependencies.py:133 Dense seleccionado pero faltan index/id_map; fallback a sparse.
WARNING  src.adapters.retrieval.sparse_bm25:sparse_bm25.py:34 WARNING: Document corpus it's empty. BM25 will not be initialized.
___________________________________________________________________________________________________________ test_init_rag_service_populates_db_from_csv_if_empty ___________________________________________________________________________________________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f9e08b50440>, tmp_path = PosixPath('/tmp/pytest-of-jd/pytest-57/test_init_rag_service_populate0'), caplog = <_pytest.logging.LogCaptureFixture object at 0x7f9e08b90910>, reset_rag_service_singleton = None

    def test_init_rag_service_populates_db_from_csv_if_empty(
        monkeypatch,
        tmp_path: Path,
        caplog, # <------------------ AÑADE caplog COMO ARGUMENTO
        reset_rag_service_singleton
    ):
        # Arrange
        # Asegurar que la BD en memoria (parcheada por conftest.py) esté VACÍA
        with AppSessionLocal() as db:
            db.query(DbDocument).delete()
            db.commit()
            assert db.query(DbDocument).count() == 0 # Confirmar que está vacía
    
        # Crear un dummy_faq.csv
        csv_file_path = tmp_path / "dummy_faq.csv"
        csv_data = [
            ["question", "answer"],
            ["Q1", "A1: some keywords"],
            ["Q2", "A2: more data"],
        ]
        num_data_rows = len(csv_data) - 1
    
        with open(csv_file_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=';')
            writer.writerows(csv_data)
    
        monkeypatch.setattr(global_settings, "faq_csv", str(csv_file_path))
        monkeypatch.setattr(global_settings, "csv_has_header", True)
        monkeypatch.setattr(global_settings, "openai_api_key", "sk-testkey")
        monkeypatch.setattr(global_settings, "retrieval_mode", "sparse")
    
        # Configura caplog ANTES de la acción que genera logs
        caplog.set_level(logging.INFO, logger="src.app.dependencies") # O el nombre correcto del logger
    
        importlib.reload(app_dependencies_module)
    
        # Act
    
        app_dependencies_module.init_rag_service()
    
        # Assert (DB count)
        with AppSessionLocal() as db_after_init:
            doc_count = db_after_init.query(DbDocument).count()
            print(f"DEBUG TEST: Count in DB AFTER init_rag_service call = {doc_count}") # Añade este print
>           assert doc_count == num_data_rows # Debería ser 2
E           assert 0 == 2

tests/unit/test_dependencies.py:227: AssertionError
--------------------------------------------------------------------------------------------------------------------------- Captured stdout call ---------------------------------------------------------------------------------------------------------------------------
DEBUG TEST: Count in DB AFTER init_rag_service call = 0
---------------------------------------------------------------------------------------------------------------------------- Captured log call -----------------------------------------------------------------------------------------------------------------------------
INFO     src.app.dependencies:dependencies.py:96 Asegurando tablas en sqlite:///:memory: …
INFO     src.app.dependencies:dependencies.py:106 BD vacía; poblando desde /tmp/pytest-of-jd/pytest-57/test_init_rag_service_populate0/dummy_faq.csv …
INFO     src.app.dependencies:dependencies.py:118 Insertados 2 documentos desde CSV.
INFO     src.app.dependencies:dependencies.py:55 OpenAI API key encontrada; usando OpenAIGenerator.
========================================================================================================================= short test summary info ==========================================================================================================================
FAILED tests/integration/test_api_ask.py::test_api_ask_with_openai_retrieves_and_generates - assert 1 in []
FAILED tests/integration/test_api_ask.py::test_api_ask_with_ollama_retrieves_and_generates - assert 2 in []
FAILED tests/unit/test_build.py::test_build_index_sparse - sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: documents
FAILED tests/unit/test_build.py::test_build_index_dense - sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: documents
FAILED tests/unit/test_dependencies.py::test_choose_generator_all_fail_raises_runtime_error - AssertionError: Regex pattern did not match.
FAILED tests/unit/test_dependencies.py::test_init_rag_service_dense_mode_fallback_to_sparse_if_files_missing - AssertionError: Expected fallback warning log was not found. Captured logs:
FAILED tests/unit/test_dependencies.py::test_init_rag_service_populates_db_from_csv_if_empty - assert 0 == 2
ERROR tests/integration/test_api_ask.py::test_api_ask_validation_error_wrong_type - sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: qa_history
ERROR tests/integration/test_api_ask.py::test_history_endpoint_records_and_retrieves_qa - sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: qa_history